---
DOI: 10/cfv4kn
Date: 2011
Rating: 5/5
Title: "Formative assessment: a critical review"
ShortSummary: ""
annotation-target: bennettFormativeAssessmentCritical2011.pdf
---


#### [Formative assessment: a critical review](bennettFormativeAssessmentCritical2011.pdf)
**

#üí•

> [!tldr] Summary
> A short summary - or an abstract in 3 sentences, relating to YOU. What did YOU find interesting about this paper. 

> [!cite] Bibliography
>Bennett, R. E. (2011). Formative assessment: A critical review. _Assessment in Education: Principles, Policy & Practice_, _18_(1), 5‚Äì25. [https://doi.org/10/cfv4kn](https://doi.org/10/cfv4kn)

> [!quote] Quotable
> Imagine you would quote this paper in your publication. How would you do it? It is probably just one sentence followed by the reference. It is the most intense condensation of the information in this paper and forces you to be on point. 
> 
> You can have multiple alternatives. 


#### Aim of Paper


#### Key insights 


#### Related

#### Annotations


The distinction between the summative and formative roles was first proposed by Scriven (1967) in the context of programme evaluation (Black and Wiliam 2003; Wiliam and Thompson 2008). For Scriven, summative evaluation provided information to judge the overall value of an educational programme (as compared with some alternative), whereas the results of formative evaluation were targeted at facilitating programme improvement. 

 

More interesting from a definitional perspective is that, with its recent ‚Äòreturn‚Äô to US education from abroad, the concept has become somewhat confused. 

 

According to the September 17, 2007 edition of EdWeek, the ‚ÄòTest industry [is] split over ‚Äúformative‚Äù assessment‚Äô, so much so that ‚ÄòTesting expert Richard J. Stiggins ... has stopped using the term ...‚Äô (Cech 2007, 1). 

 

The ‚Äòsplit‚Äô referenced by EdWeek has on one side those who believe ‚Äòformative assessment‚Äô refers to an instrument (e.g., Pearson 2005), as in a diagnostic test, an ‚Äòinterim‚Äô assessment, or an item bank from which teachers might create those tests. 

 

The other side of this split ‚Äì populated more by educators and researchers than test publishers ‚Äì is the view that ‚Äò... formative assessment is not a test but a process...‚Äô (Popham 2008, 6). In this view, the process produces not so much a score as a qualitative insight into student understanding (Shepard 2008). This camp further argues that the distinguishing characteristic is ‚Äò ... when the [results are] actually used to adapt the teaching to meet student needs‚Äô (Black and Wiliam 1998a, 140). 

 

Arguably, each position is an oversimplification. It is an oversimplification to define formative assessment as an instrument because even the most carefully constructed, scientifically supported instrument is unlikely to be effective instructionally if the process surrounding its use is flawed. Similarly, it is an oversimplification to define formative assessment as a process since even the most carefully constructed process is unlikely to work if the ‚Äòinstrumentation‚Äô, or methodology, being used in that process is not well-suited for the intended purpose. 

 

‚ÄòProcess‚Äô cannot somehow rescue unsuitable instrumentation, nor can instrumentation save an unsuitable process. A strong conceptualisation needs to give careful attention to each component, as well as to how the two components work together to provide useful feedback 

 

Many advocates of the process view appear to prefer, ‚Äòassessment for learning‚Äô, employing ‚Äòassessment of learning‚Äô to denote ‚Äòsummative assessment‚Äô. From a definitional perspective, however, this substitution is potentially problematic in that it absolves summative assessment from any responsibility for supporting learning. Further, it, too, potentially leads to oversimplifying what is, in fact, a more complex relationship. 

 

The relationship is more complex because a summative assessment should fulfil its primary purpose of documenting what students know and can do but, if carefully crafted, should also successfully meet a secondary purpose of support for learning. Such support may be provided in at least three ways. First, if the content, format and design of the test offer a sufficiently rich domain representation, preparing for the summative test can be a valuable learning experience (Shepard 2006). 

 

Second, recent research suggests that taking a test can both enhance learning by strengthening the representation of information retrieved during the test and also slow the rate of forgetting (Rohrer and Pashler 2010). 

 

A final way in which summative assessment may support learning is by providing a limited type of formative information. There is no claim that just any summative assessment can support learning effectively; only those summative tests that are designed to fulfil that subsidiary purpose by, for example, linking performance to theoretically or empirically based learning progressions (Corcoran, Mosher, and Rogat 2009; Popham 2008, 23), or mapping key tasks to the score scale (Zwick et al. 2001). With such a test, the teacher may be able to identify particular students needing more focused formative follow-up or content that may need to be re-taught presently, or taught differently next cycle. 

 

By the same token, well-designed and implemented formative assessment should be able to suggest how instruction should be modified, as well as suggest impressionistically to the teacher what students know and can do. Thus, we should be able to design assessment systems in which summative tests, besides fulfilling their primary purposes, routinely advance learning, and formative assessments routinely add to the teacher‚Äôs overall informal judgments of student achievement (see Table 1). 

 

The distinction between the summative and formative roles was first proposed by Scriven (1967) in the context of programme evaluation (Black and Wiliam 2003; Wiliam and Thompson 2008). For Scriven, summative evaluation provided information to judge the overall value of an educational programme (as compared with some alternative), whereas the results of formative evaluation were targeted at facilitating programme improvement. 

 

According to the September 17, 2007 edition of EdWeek, the ‚ÄòTest industry [is] split over ‚Äúformative‚Äù assessment‚Äô, so much so that ‚ÄòTesting expert Richard J. Stiggins ‚Ä¶ has stopped using the term ‚Ä¶‚Äô (Cech 2007, 1). 

 

‚ÄòProcess‚Äô cannot somehow rescue unsuitable instrumentation, nor can instrumentation save an unsuitable process. A strong conceptualisation needs to give careful attention to each component, as well as to how the two components work together to provide useful feedback. 

 

Many advocates of the process view appear to prefer, ‚Äòassessment for learning‚Äô, employing ‚Äòassessment of learning‚Äô to denote ‚Äòsummative assessment‚Äô. From a definitional perspective, however, this substitution is potentially problematic in that it absolves summative assessment from any responsibility for supporting learning. Further, it, too, potentially leads to oversimplifying what is, in fact, a more complex relationship. 

 




%% Import Date: 2023-04-27T06:44:03.103-07:00 %%
