---
DOI: 10/gj5ngz
Date: 2020
Rating: 0/5
Title: "Assessment Literacy in College Teaching: Empirical Evidence on the Role and Effectiveness of a Faculty Training Course"
ShortSummary: ""
annotation-target: masseyAssessmentLiteracyCollege2020.pdf
---


#### [Assessment Literacy in College Teaching: Empirical Evidence on the Role and Effectiveness of a Faculty Training Course](masseyAssessmentLiteracyCollege2020.pdf)
*Authors*



> [!tldr] Summary
> A short summary - or an abstract in 3 sentences, relating to YOU. What did YOU find interesting about this paper. 

> [!cite] Bibliography
>Massey, K. D., DeLuca, C., & LaPointe-McEwan, D. (2020). Assessment Literacy in College Teaching: Empirical Evidence on the Role and Effectiveness of a Faculty Training Course. _To Improve the Academy_, _39_(1). [https://doi.org/10/gj5ngz](https://doi.org/10/gj5ngz)

> [!quote] Quotable
> Imagine you would quote this paper in your publication. How would you do it? It is probably just one sentence followed by the reference. It is the most intense condensation of the information in this paper and forces you to be on point. 
> 
> You can have multiple alternatives. 


#### Aim of Paper


#### Key insights 


#### Related

#### Annotations


In many disciplines, postsecondary education (PSE) faculty members have little formal preparation in the art and science of teaching, curriculum design, and assessment (Knapper, 2010). 

 

proaches to teaching are highly variable and frequently associated with their own experiences as learners (Colbeck et al., 2002; Kember & Kwan, 2000; Knapper, 2010). 

 

As a result, faculty members often use traditional, didactic, teacher-centered instruction with minimal integration of formative feedback and learner-driven assessments. While most instruction in PSE relies on traditional techniques, research has consistently noted that students benefit more from engaging in active rather than passive learning situations and value feedback-rich learning contexts (Komarraju & Karau, 2008; Kuh et al., 2006; Machemer & Crawford, 2007). Accordingly, it is not surprising that PSE instruction has been repeatedly critiqued for lacking pedagogical innovation and cultivating a learning culture driven by exam-based summative measures of student achievement (Yorke, 2003). 

 

In an effort to change the culture of assessment within universities and colleges, faculty training opportunities are beginning to focus on enhancing instructors’ conceptions of student assessment toward more contemporary approaches. Contemporary approaches to assessment in PSE recognize the role and important function of summative testing but also encourage an integrated approach to assessment that utilizes formative feedback and dialogical assessment structures to propel learning forward (Boud, 2000; Nicol & Macfarlane-Dick, 2006). 

 

Changing faculty members’ approaches to student assessment is challenging. In addition to their entrenched beliefs about the role and form of assessment within specific disciplines, shifting toward a more balanced orientation between summative and formative assessment approaches is increasingly difficult given current accountability mandates and the highly competitive cultures evident within many univer- 

 

sities (Taras, 2005, 2007). Despite evidence that direct training in teaching and learning methods provided by instructional development programs can lead to positive impacts on student learning (Condon et al., 2016; Perez et al., 2012), few studies have examined how these programs contribute toward shifts in faculty members’ understandings of, confidence in, and subsequent adoption of contemporary assessment practices (Fishman et al., 2003). 

 

Student assessment in PSE continues to undergo reforms as constructivist teaching methodologies are more widely adopted, as accountability requirements intensify, and as assessment is increasingly recognized as having potential to improve teaching and learning (Taras, 2005, 2007). Requirements from accreditors and other agencies have increased institutional efforts to measure student learning, making assessment more important than ever. It is not likely that the focus of accreditation requirements on assessment will diminish any time soon, so institutional efforts to document, understand, and improve student 

 

learning must continue (Krzykowski & Kinser, 2014). 

 

As the demand for assessment literacy among postsecondary instructors increases, there is a greater need to understand how new faculty members develop their competency in using effective and contemporary classroom assessments within their instructional practice. 

 

Advances in cognitive science have enhanced our understanding of how students learn and have had significant implications for assessment practices. Research over the last several decades has supported an increased focus on constructivist teaching methods that help students to actively assimilate and accommodate new material as a result of active engagement in authentic learning experiences and feedbackdriven learning tasks (Black & Wiliam, 1998; Gardner, 2006). Compared to traditional instructional approaches, in which students are seen as passive receivers of information, current thinking about how students learn elevates assessment beyond its summative means to a central component of active learning. 

 

In this view, students are provided with ongoing feedback on their learning in relation to defined learning outcomes. These ongoing assessments are formative (i.e., not graded) and used as the basis for remediation or acceleration of learning. In addition, students are encouraged to take ownership of their own learning trajectories by using assessment information to direct their study. This contemporary view of assessment has required institutions to promote new assessment practices and thus support faculty members in designing and integrating constructivist assessment methods aimed at enhancing student learning, not just measuring it (Shepard, 2000). In PSE, instructors must balance this newer formative conception of assessment with traditional summative functions in order to support as well as evaluate student learning. 

 

Until only recently, the predominant assumption with regard to preparing PSE faculty for their role as teachers has been that a trained and skilled researcher or subject matter expert would naturally be an effective teacher. Seen as dichotomous by some, the enduring struggle between research preparation and teaching preparation still lingers today; however, it is now generally acknowledged that at least some direct preparation for teaching is essential (Austin, 2003; Hubball & Burt, 2006). 

 

While terms such as professional development and faculty development typically refer to initiatives concerning the entire career development of faculty (Centra, 1989), including activities designed to enhance one’s teaching, research, and administration activities (Sheets & Schwenk, 1990), the more specific term instructional development refers to activities explicitly aimed at developing faculty members in their role as teachers (Stes et al., 2010). 

 

Several factors have persuaded PSE leaders in the last few decades that instructional development programs are worthwhile initiatives. Specifically, evidence has been accumulating of the ineffectiveness of the traditional, teacher-centered ways of teaching (Gardiner, 1998). Lectures, for example, have been shown to only support lower levels of learning, and students do not retain even this knowledge very long (Bligh, 2000). 

 

Research reviewed by Stes et al. (2010), together with more recent studies, have demonstrated positive impacts on faculty in terms of their attitudes toward teaching and learning (Bennett & Bennett, 2003; Howland & Wedman, 2004), conceptions of teaching (Gibbs & Coffey, 2004; Postareff et al., 2007), learning new concepts and principles (Howland & Wedman, 2004; Nasmith et al., 1997), and acquiring or improving teaching skills (Dixon & Scott, 2003; Pfund et al., 2009). Previous research has also examined the impacts of instructional development on students and have demonstrated positive changes in student perceptions (Gibbs & Coffey, 2004; Medsker, 1992), behaviors (Howland & Wedman, 2004; Stepp-Greany, 2004), and learning outcomes (Brauchle & Jerich, 1998; Condon et al., 2016; Perez et al., 2012; Stepp-Greany, 2004). 

 

Studies have consistently demonstrated that faculty development programs are generally assessed using only superficial means (e.g., Beach et al., 2016; Chism & Szabó, 1998; Hines, 2009). Findings from Beach et al. (2016) indicate that as the complexity of the assessment approach increases (e.g., measuring the change in teaching practice or student learning), the percentage of use declines. Specifically, the reporting of the effects of faculty development programs more often takes the form of tracking participation numbers and participant self-report satisfaction and rarely includes data on an increase in the knowledge or skills of participants or a change in the practice of participants, even more rarely paying attention to changes in the learning of the students served by participants and/or changes in the institution’s culture of teaching. The recent work of Condon et al. (2016) offers a rare example of a sustained effort to provide measurable evidence that faculty development leads to improved instruction and improved student learning. 

 

Within PSE contexts, there is a core difference in conceptions of assessment when learning is situated within an “assessment culture” versus a “testing culture” (Birenbaum, 1996, 2003). The traditional testing culture is based on the behaviorist model of learning, focusing on objective and standardized testing with the practice of testing as separate from instruction (Shepard, 2000). In this testing culture, multiple-choice and close-ended assessments that focus on memorized knowledge are typical test formats. In contrast, an assessment culture shifts assessment toward a socio-constructivist learning paradigm in which assessments are opportunities for learning as mediated by other students’ learning and teachers’ responsive instruction (Shepard, 2000). In such a culture, assessments are used both formatively and summatively but are reflective of the enacted curriculum and students’ constructed understandings (Birenbaum, 2003). 

 

Drawing on the work of DeLuca et al. (2013), we explicate four conceptions of assessment that shape faculty members’ practices. These conceptions are (a) assessment as testing, (b) assessment as format, (c) assessment as purpose, and (d) assessment as process. 

 

characterized as regarding assessment primarily as measuring the success of knowledge transmission. This conception of assessment is common among educators who regard teaching as simply the transmission of knowledge and are therefore likely to view assessment as an activity that follows learning, rather than as an integral and formative element of learning itself (Parpala & Lindblom-Ylänne, 2007). 

 

The conception of assessment as testing is rooted in the dominant paradigm of the 20th century, which Shepard (2000) associates with behaviorist learning theories, social efficiency, and scientific measurement, all of which negate the formative role of assessment in teaching and learning. 

 

based on the understanding that assessment can take on a variety of forms, beyond the narrow view of testing. The methods used by faculty to assess student learning in PSE has expanded considerably in recent decades. Once characterized only by multiple-choice tests, traditional essays, and research papers (Sambell et al., 1997), assessment in the PSE context now often includes portfolios, projects, self- and peer-assessment, simulations, and other innovative methods (Struyven et al., 2005). If assessment tasks are representative of the context being studied and both relevant and meaningful to those involved, then they may be described as authentic. The authenticity of tasks and activities is what sets innovative assessments apart from more traditional and contrived assessments (Birenbaum, 2003; Gulikers et al., 2004). Flexibility in assessment formats can be seen as a first step toward a more student-led pedagogy that engages students in the assessment process (Irwin & Hepplestone, 2012). 

 

An assessment as purpose orientation encourages multiple uses for assessment within teaching, learning, and administrative processes. Following Bloom et al. (1971), a distinction is typically made between formative and summative assessment. Summative assessment is concerned with determining the extent to which curricular objectives have been received, whereas 

 

formative assessment is conceptualized as the “systematic evaluation in the process of curriculum construction, teaching, and learning for the purposes of improving any of these three processes” (Bloom et al., 1971, p. 117). The distinction between formative and summative assessment, however, is often blurred (Boud, 2000). For example, assessments activities such as course assignments are often designed to be simultaneously formative and summative. Activities can be formative because the student is provided feedback from which to learn, and they can be summative because the grade awarded contributes to the overall grade for the course. 

 

The final conception, assessment as process, is closely linked to assessment as, for, and of learning and conceptualizes assessment as a process of interpretation and integration. Pellegrino et al. (2001) state that “assessment is a process of reasoning from evidence” (p. 36). While recognizing that assessments used in various contexts, for differing purposes, often look quite different, this conception of assessment focuses on the fact that all assessment activities share the common principle of always being a process of reasoning from evidence. To conceive of assessment in this way is to understand that without a direct pipeline into a student’s mind, the process of assessing what a student knows and can do is not straightforward. Various tools and techniques must be employed by educators to observe students’ behavior and generate data that can be used to draw reasonable inferences about what students know (Popham, 2013). 

 

Arguably, to apply one’s understanding of assessment effectively, a postsecondary instructor must also be confident in their assessment knowledge and skills. The construct of self-efficacy in social cognitive theory (Bandura, 1986) suggests that when an individual feels competent and has confidence in completing a task, they will choose to engage in it. In contrast, when an individual feels incompetent and lacks confidence in a task, they will avoid engaging in it. It is therefore critical that faculty members not only develop complex and more nuanced conceptions of assessment but also feel confident in their assessment abilities in order to fully engage in the process of assessment. 

 

lthough not yet widely explored in the context of PSE, assessment confidence is a concept considered in K–12 education literature, often understood as a teacher’s self-perceived confidence in administering various approaches of assessments (Ludwig, 2014; Stiggins et al., 2004). In their study investigating the assessment confidence of preservice teacher candidates, DeLuca and Klinger (2010) conceptualized three domains of assessment confidence: —confidence in assessment practice, assessment theory, and assessment philosophy. DeLuca et al. (2013) identified two principal components of assessment confidence: confidence in using practical assessment approaches to measure student learning and confidence in engaging in assessment praxis. Praxis, as differentiated from practice, is the dynamic interplay between thought and action involving a continuous process of understanding, interpretation, and application. 

 

Conceptions of Assessment Participants’ conceptions of assessment developed from an initial view of assessment as testing to more complex conceptions of assessment as purpose and process. 

 

In pre-questionnaire open responses, participants’ descriptions of assessment were simplistic and concise in nature, emphasizing the summative role of assessment. Pre-questionnaire responses generally described assessment as a means to “test students,” “measure learning,” and “evaluate what students know.” Post-questionnaire responses consistently demonstrated participants’ richer and expanding conceptions of assessment that included both purpose and process. Furthermore, all participants’ post-questionnaire responses shifted beyond primarily summative conceptions of assessment to include the formative role of assessment as well. 

 

Overall, these results show that by the end of the instructional development course, participants’ primary 

 

conceptions of assessment had shifted to emphasize assessment as a formative process that supports both teaching and learning. 

 

The most frequent composite score on the pre-questionnaire was associated with the conception of assessment as testing, whereas assessment as purpose was the most frequent conception on the post-questionnaire. Specifically, the most frequently mentioned purpose of assessment on the postquestionnaire was formative. 

 

As participants’ conceptions of assessment increased in complexity, their confidence in assessment approaches and praxis also increased. Taken together, these figures suggest the importance of 

 

instructional development courses designed to foster more complex conceptions of assessment in order to positively impact college instructors’ confidence in both practical assessment approaches and assessment praxis. 

 

Although previous studies have investigated K–12 teachers’ conceptions of assessment (Brown & Harris, 2010; DeLuca et al., 2013), there is a lack of research in this area with respect to PSE instructors. This lack of research is problematic given the known influence of assessmentbased teaching on student learning (Boud, 2000; Nicol & MacfarlaneDick, 2006) and the persistent critiques on the quality of PSE instructional practices (Yorke, 2003). 

 

Specifically, our interest is to help support a shift from a testing culture to an assessment culture within PSE classrooms. An assessment culture integrates feedback-rich tasks throughout learning periods and leverages formative data to enhance teaching and learning (Birenbaum, 1996, 2003). Accordingly, we follow Shepard’s (2000) conception of a socioconstructivist orientation in which assessment not only provides evidence of student learning (i.e., summative) but also shapes what is learned and how students engage in learning. Based on a sample of 27 faculty members enrolled in a semesterlong instructor training course at a two-year college in Texas, this study provides initial evidence that faculty members can develop confidence in assessment while adopting increasingly complex conceptions of assessment. 

 

pants shifted their view of assessment from a mostly traditional, teacher-centered perspective to a more student-centered understanding that recognizes the importance of feedback to guide and improve student learning. 

 

Hence the results of this 

 

research demonstrate the potential for explicit training in assessment practices to positively shift faculty understandings of assessment from simplistic conceptions to more complex understandings. 

 

Faculty participants also expressed significantly greater confidence in factor components related to both assessment praxis and assessment practice. 

 

Following Guskey’s (1986) seminal research, we support the notion that changes in practice will facilitate further changes in an instructor’s conceptual understandings about teaching and assessment. Instructors with greater confidence via an instructional development course are more likely to implement new practices and subsequently further shift their conceptions of assessment. 

 

We recognize that a single training course will not sufficiently support faculty members in continuing to refine their assessment practices. Developing the art and science of assessment is a career-long pursuit, and commitment to this pursuit requires sustained professional development opportunities. Our study shows that an instructional training course can stimulate faculty members’ learning, but training courses are only one means to engaging faculty members in deep learning about their instructional practices. Hence, future research needs to consider a multifaceted approach to instructional development in assessments–– a series of differentiated courses, jobembedded coaching and support, and ongoing peer mentoring. The instructional training course is solely the tip of the iceberg. If a positive assessment culture is to prevail within PSE contexts, then focusing on faculty members’ assessment literacy through sustained and differentiated assessment education appears to be a promising starting place. 

 

In many disciplines, postsecondary education (PSE) faculty members have little formal preparation in the art and science of teaching, curriculum design, and assessment (Knapper, 2010). 

 

proaches to teaching are highly variable and frequently associated with their own experiences as learners (Colbeck et al., 2002; Kember & Kwan, 2000; Knapper, 2010). 

 

As a result, faculty members often use traditional, didactic, teachercentered instruction with minimal integration of formative feedback and learnerdriven assessments. While most instruction in PSE relies on traditional techniques, research has consistently noted that students beneft more from engaging in active rather than passive learning situations and value feedbackrich learning contexts (Komarraju & Karau, 2008; Kuh et al., 2006; Machemer & Crawford, 2007). Accordingly, it is not surprising that PSE instruction has been repeatedly critiqued for lacking pedagogical innovation and cultivating a learning culture driven by exambased summative measures of student achievement (Yorke, 2003). 

 

In an effort to change the culture of assessment within universities and colleges, faculty training opportunities are beginning to focus on enhancing instructors’ conceptions of student assessment toward more contemporary approaches. Contemporary approaches to assessment in PSE recognize the role and important function of summative testing but also encourage an integrated approach to assessment that utilizes formative feedback and dialogical assessment structures to propel learning forward (Boud, 2000; Nicol & MacfarlaneDick, 2006). 

 

Changing faculty members’ approaches to student assessment is challenging. In addition to their entrenched beliefs about the role and form of assessment within specifc disciplines, shifting toward a more balanced orientation between summative and formative assessment approaches is increasingly diffcult given current accountability mandates and the highly competitive cultures evident within many univer- 

 

sities (Taras, 2005, 2007). Despite evidence that direct training in teaching and learning methods provided by instructional development programs can lead to positive impacts on student learning (Condon et al., 2016; Perez et al., 2012), few studies have examined how these programs contribute toward shifts in faculty members’ understandings of, confdence in, and subsequent adoption of contemporary assessment practices (Fishman et al., 2003). 

 

Student assessment in PSE continues to undergo reforms as constructivist teaching methodologies are more widely adopted, as accountability requirements intensify, and as assessment is increasingly recognized as having potential to improve teaching and learning (Taras, 2005, 2007). Requirements from accreditors and other agencies have increased institutional efforts to measure student learning, making assessment more important than ever. It is not likely that the focus of accreditation requirements on assessment will diminish any time soon, so institutional efforts to document, understand, and improve student 

 

learning must continue (Krzykowski & Kinser, 2014). 

 

As the demand for assessment literacy among postsecondary instructors increases, there is a greater need to understand how new faculty members develop their competency in using effective and contemporary classroom assessments within their instructional practice. 

 

Advances in cognitive science have enhanced our understanding of how students learn and have had signifcant implications for assessment practices. Research over the last several decades has supported an increased focus on constructivist teaching methods that help students to actively assimilate and accommodate new material as a result of active engagement in authentic learning experiences and feedbackdriven learning tasks (Black & Wiliam, 1998; Gardner, 2006). Compared to traditional instructional approaches, in which students are seen as passive receivers of information, current thinking about how students learn elevates assessment beyond its summative means to a central component of active learning. 

 

In this view, students are provided with ongoing feedback on their learning in relation to defned learning outcomes. These ongoing assessments are formative (i.e., not graded) and used as the basis for remediation or acceleration of learning. In addition, students are encouraged to take ownership of their own learning trajectories by using assessment information to direct their study. This contemporary view of assessment has required institutions to promote new assessment practices and thus support faculty members in designing and integrating constructivist assessment methods aimed at enhancing student learning, not just measuring it (Shepard, 2000). In PSE, instructors must balance this newer formative conception of assessment with traditional summative functions in order to support as well as evaluate student learning. 

 

Until only recently, the predominant assumption with regard to preparing PSE faculty for their role as teachers has been that a trained and skilled researcher or subject matter expert would naturally be an effective teacher. Seen as dichotomous by some, the enduring struggle between research preparation and teaching preparation still lingers today; however, it is now generally acknowledged that at least some direct preparation for teaching is essential (Austin, 2003; Hubball & Burt, 2006). 

 

While terms such as professional development and faculty development typically refer to initiatives concerning the entire career development of faculty (Centra, 1989), including activities designed to enhance one’s teaching, research, and administration activities (Sheets & Schwenk, 1990), the more specifc term instructional development refers to activities explicitly aimed at developing faculty members in their role as teachers (Stes et al., 2010). 

 

Several factors have persuaded PSE leaders in the last few decades that instructional development programs are worthwhile initiatives. Specifcally, evidence has been accumulating of the ineffectiveness of the traditional, teachercentered ways of teaching (Gardiner, 1998). Lectures, for example, have been shown to only support lower levels of learning, and students do not retain even this knowledge very long (Bligh, 2000). T 

 

Research reviewed by Stes et al. (2010), together with more recent studies, have demonstrated positive impacts on faculty in terms of their attitudes toward teaching and learning (Bennett & Bennett, 2003; Howland & Wedman, 2004), conceptions of teaching (Gibbs & Coffey, 2004; Postareff et al., 2007), learning new concepts and principles (Howland & Wedman, 2004; Nasmith et al., 1997), and acquiring or improving teaching skills (Dixon & Scott, 2003; Pfund et al., 2009). Previous research has also examined the impacts of instructional development on students and have demonstrated positive changes in student perceptions (Gibbs & Coffey, 2004; Medsker, 1992), behaviors (Howland & Wedman, 2004; SteppGreany, 2004), and learning outcomes (Brauchle & Jerich, 1998; Condon et al., 2016; Perez et al., 2012; SteppGreany, 2004). 

 

Studies have consistently demonstrated that faculty development programs are generally assessed using only superfcial means (e.g., Beach et al., 2016; Chism & Szabó, 1998; Hines, 2009). Findings from Beach et al. (2016) indicate that as the complexity of the assessment approach increases (e.g., measuring the change in teaching practice or student learning), the percentage of use declines. Specifcally, the reporting of the effects of faculty development programs more often takes the form of tracking participation numbers and participant selfreport satisfaction and rarely includes data on an increase in the knowledge or skills of participants or a change in the practice of participants, even more rarely paying attention to changes in the learning of the students served by participants and/or changes in the institution’s culture of teaching. The recent work of Condon et al. (2016) offers a rare example of a sustained effort to provide measurable evidence that faculty development leads to improved instruction and improved student learning. 

 

Within PSE contexts, there is a core difference in conceptions of assessment when learning is situated within an “assessment culture” versus a “testing culture” (Birenbaum, 1996, 2003). The traditional testing culture is based on the behaviorist model of learning, focusing on objective and standardized testing with the practice of testing as separate from instruction (Shepard, 2000). In this testing culture, multiplechoice and closeended assessments that focus on memorized knowledge are typical test formats. In contrast, an assessment culture shifts assessment toward a socioconstructivist learning paradigm in which assessments are opportunities for learning as mediated by other students’ learning and teachers’ responsive instruction (Shepard, 2000). In such a culture, assessments are used both formatively and summatively but are refective of the enacted curriculum and students’ constructed understandings (Birenbaum, 2003). 

 

characterized as regarding assessment primarily as measuring the success of knowledge transmission. This conception of assessment is common among educators who regard teaching as simply the transmission of knowledge and are therefore likely to view assessment as an activity that follows learning, rather than as an integral and formative element of learning itself (Parpala & LindblomYlänne, 2007). T 

 

based on the understanding that assessment can take on a variety of forms, beyond the narrow view of testing. The methods used by faculty to assess student learning in PSE has expanded considerably in recent decades. Once characterized only by multiplechoice tests, traditional essays, and research papers (Sambell et al., 1997), assessment in the PSE context now often includes portfolios, projects, selfand peerassessment, simulations, and other innovative methods (Struyven et al., 2005). If assessment tasks are representative of the context being studied and both relevant and meaningful to those involved, then they may be described as authentic. The authenticity of tasks and activities is what sets innovative assessments apart from more traditional and contrived assessments (Birenbaum, 2003; Gulikers et al., 2004). Flexibility in assessment formats can be seen as a frst step toward a more studentled pedagogy that engages students in the assessment process (Irwin & Hepplestone, 2012). 

 

An assessment as purpose orientation encourages multiple uses for assessment within teaching, learning, and administrative processes. Following Bloom et al. (1971), a distinction is typically made between formative and summative assessment. Summative assessment is concerned with determining the extent to which curricular objectives have been received, whereas 

 

formative assessment is conceptualized as the “systematic evaluation in the process of curriculum construction, teaching, and learning for the purposes of improving any of these three processes” (Bloom et al., 1971, p. 117). The distinction between formative and summative assessment, however, is often blurred (Boud, 2000). For example, assessments activities such as course assignments are often designed to be simultaneously formative and summative. Activities can be formative because the student is provided feedback from which to learn, and they can be summative because the grade awarded contributes to the overall grade for the course. 

 

The fnal conception, assessment as process, is closely linked to assessment as, for, and of learning and conceptualizes assessment as a process of interpretation and integration. Pellegrino et al. (2001) state that “assessment is a process of reasoning from evidence” (p. 36). While recognizing that assessments used in various contexts, for differing purposes, often look quite different, this conception of assessment focuses on the fact that all assessment activities share the common principle of always being a process of reasoning from evidence. To conceive of assessment in this way is to understand that without a direct pipeline into a student’s mind, the process of assessing what a student knows and can do is not straightforward. Various tools and techniques must be employed by educators to observe students’ behavior and generate data that can be used to draw reasonable inferences about what students know (Popham, 2013). 

 

Arguably, to apply one’s understanding of assessment effectively, a postsecondary instructor must also be confdent in their assessment knowledge and skills. The construct of selfeffcacy in social cognitive theory (Bandura, 1986) suggests that when an individual feels competent and has confdence in completing a task, they will choose to engage in it. In contrast, when an individual feels incompetent and lacks confdence in a task, they will avoid engaging in it. It is therefore critical that faculty members not only develop complex and more nuanced conceptions of assessment but also feel confdent in their assessment abilities in order to fully engage in the process of assessment. 

 

lthough not yet widely explored in the context of PSE, assessment confdence is a concept considered in K– 12 education literature, often understood as a teacher’s selfperceived confdence in administering various approaches of assessments (Ludwig, 2014; Stiggins et al., 2004). In their study investigating the assessment confdence of preservice teacher candidates, DeLuca and Klinger (2010) conceptualized three domains of assessment confdence: — confdence in assessment practice, assessment theory, and assessment philosophy. DeLuca et al. (2013) identifed two principal components of assessment confdence: confdence in using practical assessment approaches to measure student learning and confdence in engaging in assessment praxis. Praxis, as differentiated from practice, is the dynamic interplay between thought and action involving a continuous process of understanding, interpretation, and application. 

 

Overall, these results show that by the end of the instructional development course, participants’ primary 

 

conceptions of assessment had shifted to emphasize assessment as a formative process that supports both teaching and learning. 

 

As participants’ conceptions of assessment increased in complexity, their confdence in assessment approaches and praxis also increased. Taken together, these fgures suggest the importance of 

 

instructional development courses designed to foster more complex conceptions of assessment in order to positively impact college instructors’ confdence in both practical assessment approaches and assessment praxis. 

 

Although previous studies have investigated K– 12 teachers’ conceptions of assessment (Brown & Harris, 2010; DeLuca et al., 2013), there is a lack of research in this area with respect to PSE instructors. This lack of research is problematic given the known infuence of assessmentbased teaching on student learning (Boud, 2000; Nicol & MacfarlaneDick, 2006) and the persistent critiques on the quality of PSE instructional practices (Yorke, 2003). 

 

Specifcally, our interest is to help support a shift from a testing culture to an assessment culture within PSE classrooms. An assessment culture integrates feedbackrich tasks throughout learning periods and leverages formative data to enhance teaching and learning (Birenbaum, 1996, 2003). Accordingly, we follow Shepard’s (2000) conception of a socioconstructivist orientation in which assessment not only provides evidence of student learning (i.e., summative) but also shapes what is learned and how students engage in learning. Based on a sample of 27 faculty members enrolled in a semesterlong instructor training course at a twoyear college in Texas, this study provides initial evidence that faculty members can develop confdence in assessment while adopting increasingly complex conceptions of assessment. 

 

pants shifted their view of assessment from a mostly traditional, teachercentered perspective to a more studentcentered understanding that recognizes the importance of feedback to guide and improve student learning. 

 

Hence the results of this 

 

research demonstrate the potential for explicit training in assessment practices to positively shift faculty understandings of assessment from simplistic conceptions to more complex understandings. A 

 

Following Guskey’s (1986) seminal research, we support the notion that changes in practice will facilitate further changes in an instructor’s conceptual understandings about teaching and assessment. Instructors with greater confdence via an instructional development course are more likely to implement new practices and subsequently further shift their conceptions of assessment. 

 




%% Import Date: 2023-03-30T06:09:31.026-07:00 %%
